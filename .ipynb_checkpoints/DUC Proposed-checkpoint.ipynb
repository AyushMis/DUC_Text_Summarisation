{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "from tqdm import tqdm\n",
    "import nbimporter\n",
    "import warnings\n",
    "import gensim\n",
    "\n",
    "\n",
    "import Utilities as utility\n",
    "print ('IMPORTING MODEL')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../dataset/GoogleNews-vectors-negative300.bin', binary=True) \n",
    "print ('IMPORTING COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_scores = utility.loadObj('rake_scores')\n",
    "stats_summary = utility.loadObj('stats_summary')\n",
    "doc_summary_pair = utility.loadObj('test_doc_summary_pair')\n",
    "combined_rake = []\n",
    "combined_stats = []\n",
    "temp = []\n",
    "for pair in doc_summary_pair:\n",
    "    doc = pair[0]\n",
    "    if doc == '\\n':\n",
    "        continue\n",
    "    temp.append(pair)\n",
    "doc_summary_pair = temp\n",
    "print ('FINISHED DATA PREPRATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_score(summaryBigram,humanBigram):\n",
    "    count = 0\n",
    "    for element in humanBigram:\n",
    "        if element in summaryBigram:\n",
    "            count+=1\n",
    "    return(count/len(humanBigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pair,stats_summary_element,rake_score_element in tqdm(zip(doc_summary_pair,stats_summary,rake_scores)):\n",
    "    try:\n",
    "        doc = pair[0]\n",
    "        sentence_list = doc.split('.')\n",
    "        clean_statistical_summery = []\n",
    "        clean_key_phrase_sentence = []\n",
    "        clean_semantical_sentences = []\n",
    "        included_sentence = []\n",
    "\n",
    "        for sentences in stats_summary_element:\n",
    "            if len(sentences) > 3:\n",
    "                clean_statistical_summery.append(' '.join(sentences))\n",
    "\n",
    "        for sentences in sentence_list:\n",
    "            if len(utility.simpleRemoveStopWords(sentences)) > 3:\n",
    "                clean_semantical_sentences.append(' '.join(utility.simpleRemoveStopWords(sentences)))\n",
    "                included_sentence.append(sentences)\n",
    "\n",
    "        for sentences in rake_score_element:\n",
    "            if len(utility.simpleRemoveStopWords(sentences[1])) > 3:\n",
    "                clean_key_phrase_sentence.append(' '.join(utility.simpleRemoveStopWords(sentences[1])))\n",
    "\n",
    "        instance = WmdSimilarity(clean_semantical_sentences, model)\n",
    "        similarity_key_phrase = instance[clean_key_phrase_sentence[0]]\n",
    "        similarity_statistical = instance[clean_statistical_summery[0]]\n",
    "        threshold_percent = 0.70\n",
    "\n",
    "        key_phrase_summary = []\n",
    "        statistical_summary = []\n",
    "\n",
    "        for i in range(0,len(similarity_key_phrase)):\n",
    "            if similarity_key_phrase[i] < threshold_percent:\n",
    "                key_phrase_summary.append(included_sentence[i])\n",
    "\n",
    "        for i in range(0,len(similarity_statistical)):\n",
    "            if similarity_statistical[i] < threshold_percent:\n",
    "                statistical_summary.append(included_sentence[i])\n",
    "\n",
    "\n",
    "        stat_sem_summary = ' '.join(statistical_summary).replace('\\n','')\n",
    "        rake_sem_summary = ' '.join(key_phrase_summary).replace('\\n','')\n",
    "        human_summary = pair[1]\n",
    "\n",
    "        stat_summaryBigram = utility.findGrams(stat_sem_summary.lower(), 2)\n",
    "        rake_summaryBigram = utility.findGrams(rake_sem_summary.lower(), 2)\n",
    "        humanBigram = utility.findGrams(human_summary.lower(), 2)\n",
    "\n",
    "        combined_stats.append(return_score(stat_summaryBigram,humanBigram))\n",
    "        combined_rake.append(return_score(rake_summaryBigram,humanBigram)) \n",
    "        break\n",
    "    except:\n",
    "        print ('Error Ocurred for a pair continuing for others')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sum(combined_stats)/len(combined_stats))\n",
    "print (sum(combined_rake)/len(combined_rake))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
